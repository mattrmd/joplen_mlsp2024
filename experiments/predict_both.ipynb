{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:50:39.395834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 23:50:39.395855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 23:50:39.396475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from pmlb import classification_dataset_names, regression_dataset_names\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from JOPLEn.singletask import JOPLEn\n",
    "from JOPLEn.enums import *\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestRegressor,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingRegressor,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostRegressor,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import (\n",
    "    LinearForestRegressor,\n",
    "    LinearForestClassifier,\n",
    "    LinearBoostRegressor,\n",
    "    LinearBoostClassifier,\n",
    ")\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from JOPLEn.ablation import Booster\n",
    "import lineartree as lt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from itertools import product\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from linear_operator.utils.warnings import NumericalWarning\n",
    "from sklearn.linear_model import Ridge, RidgeClassifier\n",
    "\n",
    "# Hide future warnings because ax uses deprecated functions from pandas\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# Hide unfixable warning from ax (warns about default behavior but there isn't\n",
    "# a clear way to turn the warning off)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "# Ax gives warning about non PSD matrix.\n",
    "# TODO: Should I fix this?\n",
    "warnings.simplefilter(action=\"ignore\", category=NumericalWarning)\n",
    "from ax import optimize\n",
    "from pathlib import Path\n",
    "from copy import copy, deepcopy\n",
    "import yaml\n",
    "import time\n",
    "from pprint import pprint\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from ax.utils.common.logger import ROOT_STREAM_HANDLER\n",
    "from JOPLEn.partitioner import (\n",
    "    VPartition,\n",
    "    GBPartition,\n",
    "    RFPartition,\n",
    "    VarMaxForestPartition,\n",
    "    LinearForestPartition,\n",
    "    LinearBoostPartition,\n",
    ")\n",
    "from JOPLEn.singletask import SquaredError, LogisticLoss\n",
    "from JOPLEn.enums import CellModel\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import lightgbm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nn import NN\n",
    "from sklearn.metrics import log_loss, roc_auc_score, zero_one_loss\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import sys\n",
    "\n",
    "fastel_path = Path().resolve().parent\n",
    "sys.path.append(str(fastel_path))\n",
    "\n",
    "from FASTEL.src.engine import MultiTaskTrees\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ROOT_STREAM_HANDLER.setLevel(logging.ERROR)\n",
    "\n",
    "CACHE_DIR = Path(\"ax_runs\") / \"prediction\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DS_PATH = (Path(\"..\") / \"datasets\" / \"pmlb\" / \"processed\").resolve()\n",
    "PARAM_PATH = (Path(\".\") / \"parameters\").resolve()\n",
    "PLOT_PATH = (Path(\".\") / \"plots\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many samples, causes JOPLEn to crash\n",
    "EXCLUDE = [\n",
    "    # regression\n",
    "    \"1191_BNG_pbc\",\n",
    "    \"215_2dplanes\",\n",
    "    \"1201_BNG_breastTumor\",\n",
    "    \"1196_BNG_pharynx\",\n",
    "    \"1595_poker\",\n",
    "    \"1203_BNG_pwLinear\",\n",
    "    \"594_fri_c2_100_5\",\n",
    "    \"218_house_8L\",\n",
    "    \"1193_BNG_lowbwt\",\n",
    "    \"537_houses\",\n",
    "    \"564_fried\",\n",
    "    \"344_mv\",\n",
    "    \"574_house_16H\",\n",
    "    \"573_cpu_act\",\n",
    "    \"562_cpu_small\",\n",
    "    \"1199_BNG_echoMonths\",\n",
    "    \"294_satellite_image\",\n",
    "    \"197_cpu_act\",\n",
    "    \"201_pol\",\n",
    "    \"227_cpu_small\",\n",
    "    \"503_wind\",\n",
    "    # classification\n",
    "    # \"Hill_Valley_with_noise\",\n",
    "    # \"Hill_Valley_without_noise\",\n",
    "    # \"breast_cancer_wisconsin\",\n",
    "    # \"appendicitis\",\n",
    "    # \"prnn_synth\",\n",
    "    # \"sonar\",\n",
    "    # \"phoneme\",\n",
    "    # \"twonorm\",\n",
    "    # \"magic\",\n",
    "    # \"wdbc\",\n",
    "    \"adult\",\n",
    "    # crashing for some reason, fix later\n",
    "    \"Hill_Valley_without_noise\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    \"reg\": {},\n",
    "    \"class\": {},\n",
    "}\n",
    "\n",
    "for t in [\"reg\", \"class\"]:\n",
    "    for model in (PARAM_PATH / t).glob(\"*.yaml\"):\n",
    "        model_info[t][model.stem] = yaml.safe_load(open(model, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    if len(set(y_true)) == 2:\n",
    "        return float(roc_auc_score(y_true, y_pred))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_to_ordinals(feature_type, x_train, x_val, x_test):\n",
    "    cat_idxs = np.array(\n",
    "        [i for i, t in enumerate(feature_type) if t in [\"categorical\", \"binary\"]]\n",
    "    )\n",
    "\n",
    "    if len(cat_idxs) > 0:\n",
    "        # lgbm doesn't like negative values for categorical values. Technically\n",
    "        # negative indicates that the value is actually quantized scalar, but\n",
    "        # PMLB doesn't distinguish these from regular categorical values.\n",
    "        x_train = x_train.copy()\n",
    "        x_val = x_val.copy()\n",
    "\n",
    "        enc = OrdinalEncoder().fit(x_train[:, cat_idxs])\n",
    "\n",
    "        x_train[:, cat_idxs] = enc.transform(x_train[:, cat_idxs])\n",
    "        x_val[:, cat_idxs] = enc.transform(x_val[:, cat_idxs])\n",
    "\n",
    "        if x_test is not None:\n",
    "            x_test = x_test.copy()\n",
    "            x_test[:, cat_idxs] = enc.transform(x_test[:, cat_idxs])\n",
    "\n",
    "    return cat_idxs, x_train, x_val, x_test\n",
    "\n",
    "\n",
    "def loss(\n",
    "    y_true: np.ndarray, y_pred: np.ndarray, loss_str: str\n",
    ") -> tuple[float, dict[str, float]]:\n",
    "    if loss_str in [\"mse\", \"rmse\", \"regression\", False, \"reg:squarederror\"]:\n",
    "        return float(rmse(y_true, y_pred)), {}\n",
    "    elif loss_str in [\"log_loss\", \"binary\", True, \"reg:logistic\"]:\n",
    "        y_class_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        return float(log_loss(y_true, y_pred)), {\n",
    "            \"auc\": float(roc_auc_score(y_true, y_pred)),\n",
    "            \"zo_loss\": float(zero_one_loss(y_true, y_class_pred)),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss function: {loss_str}\")\n",
    "\n",
    "\n",
    "def timer_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        return (result, start_time, end_time, elapsed_time)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_lgbm(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    params = deepcopy(params)\n",
    "\n",
    "    early_stopping_rounds = params.pop(\"early_stopping_rounds\")\n",
    "    model = ModelClass(**params)\n",
    "\n",
    "    is_classifier = issubclass(ModelClass, ClassifierMixin)\n",
    "\n",
    "    early_stop = lightgbm.early_stopping(\n",
    "        stopping_rounds=early_stopping_rounds,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    cat_idxs, x_train, x_val, x_test = convert_to_ordinals(\n",
    "        feature_type, x_train, x_val, x_test\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train.flatten(),\n",
    "        # TODO: Need to re-enable validation set\n",
    "        eval_set=[(x_val, y_val.flatten())],\n",
    "        # verbose=-1,\n",
    "        callbacks=[early_stop],\n",
    "        categorical_feature=cat_idxs,\n",
    "    )\n",
    "\n",
    "    val_pred = (\n",
    "        model.predict_proba(x_val)[:, 1] if is_classifier else model.predict(x_val)\n",
    "    )\n",
    "\n",
    "    val_error = loss(y_val, val_pred, params[\"objective\"])\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        y_pred = (\n",
    "            model.predict_proba(x_test)[:, 1]\n",
    "            if is_classifier\n",
    "            else model.predict(x_test)\n",
    "        )\n",
    "\n",
    "        test_error = loss(y_test, y_pred, params[\"objective\"])\n",
    "\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\"val\": val_error[1], \"test\": test_error[1]},\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_xgboost(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    params = deepcopy(params)\n",
    "    early_stopping_rounds = params.pop(\"early_stopping_rounds\")\n",
    "\n",
    "    model = ModelClass(**params)\n",
    "\n",
    "    is_classifier = issubclass(ModelClass, ClassifierMixin)\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train.flatten(),\n",
    "        # TODO: Need to re-enable validation set\n",
    "        eval_set=[(x_val, y_val.flatten())],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose=False,\n",
    "        eval_metric=\"logloss\" if is_classifier else \"rmse\",\n",
    "    )\n",
    "\n",
    "    val_pred = (\n",
    "        model.predict_proba(x_val)[:, 1] if is_classifier else model.predict(x_val)\n",
    "    )\n",
    "\n",
    "    val_error = loss(y_val, val_pred, params[\"objective\"])\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        y_pred = (\n",
    "            model.predict_proba(x_test)[:, 1]\n",
    "            if is_classifier\n",
    "            else model.predict(x_test)\n",
    "        )\n",
    "\n",
    "        test_error = loss(y_test, y_pred, params[\"objective\"])\n",
    "\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\"val\": val_error[1], \"test\": test_error[1]},\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_sklearn(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    rescale=False,\n",
    "    feature_type=[],\n",
    "):\n",
    "    if rescale:\n",
    "        model = Pipeline(\n",
    "            [(\"scaler\", StandardScaler()), (\"model\", ModelClass(**params))]\n",
    "        )\n",
    "    else:\n",
    "        model = ModelClass(**params)\n",
    "\n",
    "    model.fit(x_train, y_train.flatten())\n",
    "\n",
    "    is_classification = issubclass(ModelClass, ClassifierMixin)\n",
    "\n",
    "    if is_classification:\n",
    "        val_error = loss(y_val, model.predict_proba(x_val)[:, 1], True)\n",
    "    else:\n",
    "        val_error = loss(y_val, model.predict(x_val), False)\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        if is_classification:\n",
    "            y_pred = model.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "        test_error = loss(y_test, y_pred, is_classification)\n",
    "\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\"val\": val_error[1], \"test\": test_error[1]},\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model\n",
    "\n",
    "\n",
    "def train_gbr(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_rfr(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_etr(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO: compare JOPLEn to AdaBoost\n",
    "def train_abr(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_lf(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        {**params, \"base_estimator\": LinearRegression()},\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "def train_ridge(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_sklearn(\n",
    "        ModelClass,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        rescale=True,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_pen(\n",
    "    ModelType,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    params = deepcopy(params)\n",
    "    is_classification = eval(params.get(\"loss_fn\", \"SquaredError\")) == LogisticLoss\n",
    "\n",
    "    initial_params = {\n",
    "        \"partitioner\": eval(params.pop(\"partitioner\")),\n",
    "        \"n_cells\": params.pop(\"n_cells\"),\n",
    "        \"n_partitions\": params.pop(\"n_partitions\"),\n",
    "        \"random_state\": params.pop(\"random_state\"),\n",
    "    }\n",
    "\n",
    "    if \"cell_model\" in params:\n",
    "        initial_params[\"cell_model\"] = eval(params.pop(\"cell_model\"))\n",
    "\n",
    "    model = ModelType(\n",
    "        loss_fn=eval(params.pop(\"loss_fn\", \"SquaredError\")),\n",
    "        **initial_params,\n",
    "    )\n",
    "\n",
    "    if \"norm_type\" in params:\n",
    "        params[\"norm_type\"] = eval(params[\"norm_type\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        val_x=x_val,\n",
    "        val_y=y_val,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    val_error = loss(y_val, model.predict(x_val), is_classification)\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        y_pred = model.predict(x_test)\n",
    "        test_error = loss(y_test, y_pred, is_classification)\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\n",
    "                \"n_epochs\": (\n",
    "                    len(history[\"objective\"]) if \"objective\" in history else None\n",
    "                ),\n",
    "                \"val\": val_error[1],\n",
    "                \"test\": test_error[1],\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model\n",
    "\n",
    "\n",
    "def train_joplen(\n",
    "    _,  # ModelClass is not used\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    return train_pen(\n",
    "        JOPLEn,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_fastel(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    assert (\n",
    "        params.get(\"loss_criteria\", \"mse\") != \"log_loss\"\n",
    "    ), \"FASTEL does not support the logistic loss\"\n",
    "\n",
    "    xs = StandardScaler().fit(x_train)\n",
    "    x_train = xs.transform(x_train)\n",
    "    x_val = xs.transform(x_val)\n",
    "    x_test = xs.transform(x_test) if x_test is not None else None\n",
    "\n",
    "    ys = StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "    y_train = ys.transform(y_train.reshape(-1, 1))\n",
    "    y_val = ys.transform(y_val.reshape(-1, 1))\n",
    "    y_test = ys.transform(y_test.reshape(-1, 1)) if y_test is not None else None\n",
    "\n",
    "    model = MultiTaskTrees(\n",
    "        input_shape=x_train.shape[1:],\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    model.train(\n",
    "        x_train,\n",
    "        y_train.reshape(-1, 1),\n",
    "        np.ones((y_train.shape[0], 1)),\n",
    "        x_val,\n",
    "        y_val.reshape(-1, 1),\n",
    "        np.ones((y_val.shape[0], 1)),\n",
    "    )\n",
    "\n",
    "    y_val_pred = ys.inverse_transform(model.predict(x_val)[:, None])\n",
    "    val_error = loss(y_val, y_val_pred.flatten(), params.get(\"loss_criteria\", \"mse\"))\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        y_test_pred = ys.inverse_transform(model.predict(x_test)[:, None])\n",
    "        test_error = loss(\n",
    "            y_test, y_test_pred.flatten(), params.get(\"loss_criteria\", \"mse\")\n",
    "        )\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\n",
    "                \"val\": val_error[1],\n",
    "                \"test\": test_error[1],\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_nn(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test=None,\n",
    "    y_test=None,\n",
    "    feature_type=[],\n",
    "):\n",
    "    # TODO: should rescale the y values as well\n",
    "    xs = StandardScaler().fit(x_train)\n",
    "\n",
    "    loss_criteria = params.pop(\"loss_criteria\", \"mse\")\n",
    "\n",
    "    assert loss_criteria == \"mse\"\n",
    "\n",
    "    tmp_params = deepcopy(params)\n",
    "\n",
    "    model = NN(\n",
    "        hidden_layer_size=tmp_params.pop(\"hidden_layer_size\"),\n",
    "        n_hidden_layers=tmp_params.pop(\"n_hidden_layers\"),\n",
    "        activation=tmp_params.pop(\"activation\"),\n",
    "        sel_feat=False,\n",
    "    )\n",
    "    model.fit(\n",
    "        xs.transform(x_train),\n",
    "        y_train,\n",
    "        xs.transform(x_val),\n",
    "        y_val,\n",
    "        **tmp_params,\n",
    "    )\n",
    "\n",
    "    y_val_pred = model.predict(xs.transform(x_val))\n",
    "    val_error = loss(y_val, y_val_pred.flatten(), loss_criteria)\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        y_test_pred = model.predict(xs.transform(x_test))\n",
    "        test_error = loss(y_test, y_test_pred.flatten(), loss_criteria)\n",
    "        return (\n",
    "            val_error[0],\n",
    "            test_error[0],\n",
    "            model,\n",
    "            {\"val\": val_error[1], \"test\": test_error[1]},\n",
    "        )\n",
    "    else:\n",
    "        return val_error[0], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_prediction(\n",
    "    x_train,\n",
    "    x_val,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    y_test,\n",
    "    is_classification,\n",
    "):\n",
    "    if is_classification:\n",
    "        dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    else:\n",
    "        dummy = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "    dummy.fit(x_train, y_train)\n",
    "    y_pred = dummy.predict(x_test)\n",
    "\n",
    "    res = loss(y_test, y_pred, is_classification)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": dummy.__class__.__name__,\n",
    "        \"loss\": res[0],\n",
    "        \"metadata\": res[1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contains_categorical(arr: np.ndarray) -> bool:\n",
    "#     \"\"\"Checks if an array contains categorical, ordinal, binary, or nominal features\"\"\"\n",
    "#     return bool(np.any(np.all(np.mod(arr, 1) == 0, axis=0)))\n",
    "\n",
    "\n",
    "train_fn = {\n",
    "    LGBMRegressor.__name__: train_lgbm,\n",
    "    LGBMClassifier.__name__: train_lgbm,\n",
    "    XGBRegressor.__name__: train_xgboost,\n",
    "    XGBClassifier.__name__: train_xgboost,\n",
    "    GradientBoostingRegressor.__name__: train_gbr,\n",
    "    GradientBoostingClassifier.__name__: train_gbr,\n",
    "    RandomForestRegressor.__name__: train_rfr,\n",
    "    RandomForestClassifier.__name__: train_rfr,\n",
    "    ExtraTreesRegressor.__name__: train_etr,\n",
    "    ExtraTreesClassifier.__name__: train_etr,\n",
    "    JOPLEn.__name__: train_joplen,\n",
    "    LinearForestRegressor.__name__: train_lf,\n",
    "    LinearForestClassifier.__name__: train_lf,\n",
    "    Ridge.__name__: train_ridge,\n",
    "    MultiTaskTrees.__name__: train_fastel,\n",
    "    NN.__name__: train_nn,\n",
    "}\n",
    "\n",
    "\n",
    "def optimize_model(model_info, ds_path, n_trials, skip_categorical, ds_metadata):\n",
    "    ds_name = ds_path.name\n",
    "    params = model_info[\"parameters\"]\n",
    "\n",
    "    is_classification = ds_metadata[\"pmlb_metadata\"][\"target\"][\"type\"] == \"categorical\"\n",
    "\n",
    "    loss_type = \"log_loss\" if is_classification else \"rmse\"\n",
    "\n",
    "    dir_path = (\n",
    "        CACHE_DIR\n",
    "        / (\"class\" if is_classification else \"regr\")\n",
    "        / model_info[\"dir_name\"]\n",
    "        / ds_name\n",
    "    )\n",
    "    exp_path = dir_path / \"experiment.json\"\n",
    "    metadata_path = dir_path / \"metadata.yaml\"\n",
    "\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    cont_mask = np.array([t == \"continuous\" for t in ds_metadata[\"feature_type\"]])\n",
    "    bl_categorical = np.any(~cont_mask)\n",
    "\n",
    "    if np.sum(cont_mask) == 0:\n",
    "        return None\n",
    "\n",
    "    x_train = np.loadtxt(ds_path / \"x_train.csv\", delimiter=\",\")[:, cont_mask]\n",
    "    x_val = np.loadtxt(ds_path / \"x_val.csv\", delimiter=\",\")[:, cont_mask]\n",
    "    x_test = np.loadtxt(ds_path / \"x_test.csv\", delimiter=\",\")[:, cont_mask]\n",
    "    y_train = np.loadtxt(ds_path / \"y_train.csv\", delimiter=\",\")\n",
    "    y_val = np.loadtxt(ds_path / \"y_val.csv\", delimiter=\",\")\n",
    "    y_test = np.loadtxt(ds_path / \"y_test.csv\", delimiter=\",\")\n",
    "\n",
    "    if is_classification:\n",
    "        enc = LabelEncoder()\n",
    "        y_train = enc.fit_transform(y_train)\n",
    "        y_val = enc.transform(y_val)\n",
    "        y_test = enc.transform(y_test)\n",
    "\n",
    "    # if bl_categorical and skip_categorical:\n",
    "    #     return None\n",
    "\n",
    "    # if bl_categorical and not model_info[\"handles_categorical\"]:\n",
    "    #     return None\n",
    "\n",
    "    dummy_info = dummy_prediction(\n",
    "        x_train,\n",
    "        x_val,\n",
    "        x_test,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        y_test,\n",
    "        is_classification=is_classification,\n",
    "    )\n",
    "\n",
    "    if not exp_path.exists():\n",
    "        ax_client = AxClient(\n",
    "            random_seed=0,\n",
    "            verbose_logging=False,\n",
    "        )\n",
    "\n",
    "        ax_client.create_experiment(\n",
    "            name=f\"{model_info['model']}_{ds_name}\",\n",
    "            parameters=params,\n",
    "            objectives={loss_type: ObjectiveProperties(minimize=True)},\n",
    "            overwrite_existing_experiment=True,\n",
    "        )\n",
    "\n",
    "        for _ in trange(n_trials, leave=False, position=1):\n",
    "            round_params, trial_index = ax_client.get_next_trial()\n",
    "\n",
    "            try:\n",
    "                val_error, _ = train_fn[model_info[\"model\"]](\n",
    "                    eval(model_info[\"model\"]),\n",
    "                    round_params,\n",
    "                    x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_val=x_val,\n",
    "                    y_val=y_val,\n",
    "                    feature_type=[],\n",
    "                )[0]\n",
    "                ax_client.complete_trial(\n",
    "                    trial_index=trial_index, raw_data=float(val_error)\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                ax_client.abandon_trial(\n",
    "                    trial_index=trial_index,\n",
    "                    reason=str(e),\n",
    "                )\n",
    "\n",
    "        exp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ax_client.save_to_json_file(\n",
    "            filepath=exp_path,\n",
    "        )\n",
    "    else:\n",
    "        ax_client = AxClient.load_from_json_file(filepath=exp_path)\n",
    "\n",
    "    best_parameters, values = ax_client.get_best_parameters()\n",
    "\n",
    "    (val_error, test_error, model, metadata), _, _, train_time = train_fn[\n",
    "        model_info[\"model\"]\n",
    "    ](\n",
    "        eval(model_info[\"model\"]),\n",
    "        best_parameters,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        feature_type=[],\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        \"model_name\": model_info[\"model\"],\n",
    "        \"val_score\": float(val_error),\n",
    "        \"test_score\": float(test_error),\n",
    "        \"train_time\": float(train_time),\n",
    "        \"params\": best_parameters,\n",
    "        \"dummy_loss\": float(dummy_info[\"loss\"]),\n",
    "        \"contains_categorical\": \"postprocessed\" if bl_categorical else False,\n",
    "        \"metadata\": metadata,\n",
    "        \"dummy_metadata\": dummy_info[\"metadata\"],\n",
    "    }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        yaml.dump(metadata, f)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reg datasets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cfbad3c9994833a622b9d5567a6746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running class datasets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e2128113664daa92787bceecfd951f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b8766c92ec4cfb906cfc1476f66a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f2a222d46e43f28dd4bb0dc32442f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2896631a504d819f95b33622c7a967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f19b0d7c06049549213a15ab1c58e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17829775dcc24fd0b59e3e6dec53a601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b7eaa8fcca4caab35337cb835c0b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128c4674575c439196c50fb5a42a6068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/code/school/joplen/code/joplen-tests/my_env311/lib/python3.11/site-packages/botorch/optim/initializers.py:403: BadInitialCandidatesWarning: Unable to find non-zero acquisition function values - initial conditions are being selected randomly.\n",
      "  warnings.warn(\n",
      "/home/matt/code/school/joplen/code/joplen-tests/my_env311/lib/python3.11/site-packages/botorch/optim/initializers.py:403: BadInitialCandidatesWarning: Unable to find non-zero acquisition function values - initial conditions are being selected randomly.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45879b32d58647c78672bc9e4a4c3aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0614379af439baaabffa8627445f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75c30db83a3477ba9d40c68e2573df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/code/school/joplen/code/joplen-tests/my_env311/lib/python3.11/site-packages/botorch/models/utils/assorted.py:201: InputDataWarning: Input data is not standardized (mean = tensor([0.], dtype=torch.float64), std = tensor([0.], dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1612a9674ed4474a975ea1fee49a3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d839632d9de4c3db9ccd33a188b2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3fbf9ed8ac4750b7df89e3d473b0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda4a160d724112b875393f2562fef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06913dc0dfdf4090b2843115ecbc7125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379469e383044b21b2a30e7251853672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaff8be263824d8292fc3f3036648f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbfb7e287f84e16bd53a3ca8e71fe10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d25066d84934c9596043327919bf710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63812e0601914dbfb108fd9f695870e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556f542c814440f4acadf1ae0db109de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae5a063cc224587a6a3a7e9adac1c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71119f034cb483aa86efb27c6d7390f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8957f25dd7749f78c34323dd60a76ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c8b93570e44216986bf5a231215402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f630eb55923a4bb6b9c2c0d458592c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdef2ed2dcbb4dae8fc6cab6b38b9248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5282a569a24c4a4c94a520d3a66a3f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb86634d4154a69b07cf790bfac69ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46be8fc5b641f39cf6844586a5d32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202944f64cc54b24ad2ea08da51b63f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d76fdaf656349b1b82d4ac55ea7a51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf99e3971214a19804674e064a41fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545295068c0a4352b05cdfda54c780cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbc49c6ef7d4d2886af757770f1c59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ebd6acb02f49bdabea182f0b4d97c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb72f8e06f04dbb9985b7da17178ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ignored_models = [\n",
    "    \"adaboost\",\n",
    "    \"joplen_const_linforest_part\",\n",
    "    \"lf\",\n",
    "    \"et\",\n",
    "    \"joplen_const_rf_part\",\n",
    "    \"lgbm\",\n",
    "    \"fastel\",\n",
    "    \"joplen_const\",\n",
    "    \"nn\",\n",
    "    # \"gb\",  # normal GB\n",
    "    \"joplen_linear_gb_part\",\n",
    "    \"rf\",\n",
    "    \"joplen_const_gb_part_l1\",\n",
    "    \"joplen_linear_inf\",\n",
    "    \"ridge\",\n",
    "    # \"joplen_const_gb_part_l2\",  # fast joplen loss\n",
    "    \"joplen_linear_linforest_part\",\n",
    "    # \"xgboost\",  # gradient boosting with penalty term\n",
    "    \"joplen_const_gb_part_sl2\",\n",
    "    \"joplen_linear_rf_part\",\n",
    "    \"joplen_const_gb_part\",\n",
    "    \"joplen_linear\",\n",
    "]\n",
    "\n",
    "reg_datasets = [d for d in (DS_PATH / \"reg\").iterdir() if d.is_dir()]\n",
    "class_datasets = [d for d in (DS_PATH / \"class\").iterdir() if d.is_dir()]\n",
    "\n",
    "metadata = {}\n",
    "\n",
    "for name in [\"reg\", \"class\"]:\n",
    "    metadata[name] = yaml.safe_load(open(DS_PATH.parent / f\"{name}_metadata.yaml\", \"r\"))\n",
    "\n",
    "\n",
    "reg_res = defaultdict(dict)\n",
    "\n",
    "for name, lst in zip([\"reg\", \"class\"], [reg_datasets, class_datasets]):\n",
    "    print(f\"Running {name} datasets\")\n",
    "\n",
    "    itr = tqdm(lst, position=0)\n",
    "\n",
    "    for ds_path in itr:\n",
    "        if ds_path.name in EXCLUDE:\n",
    "            continue\n",
    "\n",
    "        # print(ignored_models)\n",
    "        for file_name, info in model_info[name].items():\n",
    "            if file_name in ignored_models:\n",
    "                continue\n",
    "\n",
    "            # print(f\"Running {file_name} on {ds_path.name}\")\n",
    "\n",
    "            model_str = f\"{file_name} on {ds_path.name}\"\n",
    "            itr.set_description(f\"Running {model_str : <50}\")\n",
    "            res = optimize_model(\n",
    "                info,\n",
    "                ds_path,\n",
    "                50,\n",
    "                False,\n",
    "                metadata[name][ds_path.name],\n",
    "            )\n",
    "\n",
    "            if res is not None:\n",
    "                reg_res[info[\"name\"]][ds_path.name] = res\n",
    "\n",
    "reg_res = dict(reg_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JOPLEn (constant, GB partitions, l2)': 0.10782166957511372, 'Gradient Boosting': 0.10508277419289065, 'XGBoost': 0.10078342789539156}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_strip(\n",
    "    reg_res: dict,\n",
    "    jitter: float = 0.2,\n",
    "    random_state: int = 0,\n",
    "    plot_kwargs: dict = {},\n",
    "    scatter_kwargs: dict = {},\n",
    "    only_classification: bool = False,\n",
    "    only_continuous: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a strip plot based on the list of y-values.\n",
    "    \"\"\"\n",
    "    x_values = []\n",
    "    y_labels = []\n",
    "\n",
    "    def score(vv: dict, only_classification: bool):\n",
    "        # print(vv)\n",
    "        if only_classification:\n",
    "            return vv[\"metadata\"][\"test\"][\"zo_loss\"] / vv[\"dummy_metadata\"][\"zo_loss\"]\n",
    "        else:\n",
    "            return vv[\"test_score\"] / vv[\"dummy_loss\"]\n",
    "\n",
    "    rescaled_res = {\n",
    "        k: {\n",
    "            kk: score(vv, only_classification)\n",
    "            for kk, vv in v.items()\n",
    "            if kk in classification_dataset_names\n",
    "            and vv[\"contains_categorical\"] != only_continuous\n",
    "        }\n",
    "        for k, v in reg_res.items()\n",
    "    }\n",
    "\n",
    "    rescaled_res = {k: v for k, v in rescaled_res.items() if len(v) > 0}\n",
    "\n",
    "    mean_res = {k: np.mean(list(v.values())) for k, v in rescaled_res.items()}\n",
    "\n",
    "    sorted_dict = {k: rescaled_res[k] for k in sorted(mean_res, key=mean_res.get)[::-1]}\n",
    "\n",
    "    for k, v in sorted_dict.items():\n",
    "        x_values.append(v.values())\n",
    "        y_labels.append(k)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, len(rescaled_res) * 2 / 3), **plot_kwargs)\n",
    "\n",
    "    for x_idx, val in enumerate(x_values):\n",
    "        np.random.seed(random_state)\n",
    "        # Apply jitter to x-axis positions\n",
    "        y_values = [x_idx + np.random.uniform(-jitter, jitter) for _ in val]\n",
    "        ax.scatter(val, y_values, **scatter_kwargs)\n",
    "\n",
    "    x_lim = ax.get_xlim() if only_classification else (0, 1)\n",
    "\n",
    "    for x_idx, val in enumerate(x_values[:-1]):\n",
    "        ax.hlines(x_idx + 1 / 2, *x_lim, color=\"k\", alpha=0.25)\n",
    "\n",
    "    # plot vertical line for mean for each model\n",
    "    means = [np.mean(list(val)) for val in x_values]\n",
    "    for x_value, mean in zip(range(len(x_values)), means):\n",
    "        ax.vlines(mean, x_value - 1 / 2, x_value + 1 / 2, color=\"k\")\n",
    "\n",
    "    ax.set_xlim(x_lim)\n",
    "\n",
    "    print({k: v for k, v in zip(y_labels, means)})\n",
    "\n",
    "    ax.set_yticks(range(len(y_labels)))\n",
    "    ax.set_yticklabels(y_labels)\n",
    "\n",
    "    if not only_classification:\n",
    "        ax.vlines(1, -1, len(y_labels) + 1, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_ylim(-1 / 2, len(y_labels) - 1 / 2)\n",
    "\n",
    "    plt.xlabel(\"Normalized Loss\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax, means\n",
    "\n",
    "\n",
    "ONLY_CLASSIFICATION = False\n",
    "ONLY_CONTINUOUS = False\n",
    "\n",
    "ax, means = plot_strip(\n",
    "    reg_res,\n",
    "    scatter_kwargs={\"alpha\": 0.5, \"s\": 20},\n",
    "    only_classification=ONLY_CLASSIFICATION,\n",
    "    only_continuous=ONLY_CONTINUOUS,\n",
    ")\n",
    "\n",
    "plt.xlim(0, 1 if ONLY_CLASSIFICATION else 1.5)\n",
    "\n",
    "plt.savefig(PLOT_PATH / \"reg_strip.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Random forest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m         joplen\u001b[38;5;241m.\u001b[39mappend(v[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m dummy_loss)\n\u001b[1;32m     14\u001b[0m         gb\u001b[38;5;241m.\u001b[39mappend(reg_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Boosting\u001b[39m\u001b[38;5;124m\"\u001b[39m][k][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m dummy_loss)\n\u001b[0;32m---> 15\u001b[0m         rf\u001b[38;5;241m.\u001b[39mappend(\u001b[43mreg_res\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandom forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[k][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m dummy_loss)\n\u001b[1;32m     17\u001b[0m joplen \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(joplen)\n\u001b[1;32m     18\u001b[0m gb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(gb)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Random forest'"
     ]
    }
   ],
   "source": [
    "# compute non-parametic distribution test\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "joplen, gb, rf = [], [], []\n",
    "\n",
    "for k, v in reg_res[\"JOPLEn (constant, GB partitions, l2)\"].items():\n",
    "    if k in reg_res[\"Gradient Boosting\"]:\n",
    "        if (k in classification_dataset_names) != ONLY_CLASSIFICATION:\n",
    "            continue\n",
    "\n",
    "        dummy_loss = v[\"dummy_loss\"] if ONLY_CLASSIFICATION else 1\n",
    "        joplen.append(v[\"test_score\"] / dummy_loss)\n",
    "        gb.append(reg_res[\"Gradient Boosting\"][k][\"test_score\"] / dummy_loss)\n",
    "        rf.append(reg_res[\"Random forest\"][k][\"test_score\"] / dummy_loss)\n",
    "\n",
    "joplen = np.array(joplen)\n",
    "gb = np.array(gb)\n",
    "\n",
    "print(wilcoxon(joplen, gb, alternative=\"less\"))\n",
    "print(wilcoxon(gb, rf, alternative=\"less\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ours' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mours\u001b[49m, theirs)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJOPLEn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ours' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(ours, theirs)\n",
    "plt.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\")\n",
    "plt.xlabel(\"JOPLEn\")\n",
    "plt.ylabel(\"Gradient Boosting\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rescaled_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mrescaled_res\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m ratio \u001b[38;5;241m=\u001b[39m ours \u001b[38;5;241m/\u001b[39m theirs\n\u001b[1;32m      4\u001b[0m args \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(ratio)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rescaled_res' is not defined"
     ]
    }
   ],
   "source": [
    "datasets = list(list(rescaled_res.values())[0].keys())\n",
    "\n",
    "ratio = ours / theirs\n",
    "args = np.argsort(ratio)[::-1]\n",
    "\n",
    "plt.scatter(range(len(ratio)), ratio[args])\n",
    "plt.hlines(1, 0, len(ratio), color=\"k\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"JOPLEn / Gradient Boosting\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"We do much worse on these datasets\")\n",
    "print([datasets[i] for i in args[:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [192_vineyard](https://github.com/EpistasisLab/pmlb/blob/master/datasets/192_vineyard/metadata.yaml): Small dataset, 52 samples, 2 features. May be that we just needed to use a better GB model for selecting splits\n",
    "- 645_fri_c3_500_50: Not sure what's wrong with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "\n",
    "for ds_path in reg_datasets:\n",
    "    if ds_path.name in EXCLUDE:\n",
    "        continue\n",
    "\n",
    "    x_train = np.loadtxt(ds_path / \"x_train.csv\", delimiter=\",\")\n",
    "    shapes.append(x_train.shape[1])\n",
    "\n",
    "plt.hist(shapes, bins=20)\n",
    "plt.ylabel(\"# features\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
