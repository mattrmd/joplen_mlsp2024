{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from JOPLEn.enums import NormType, CellModel\n",
    "from JOPLEn.singletask import l21_norm, linf1_norm\n",
    "from JOPLEn.singletask import JOPLEn\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "from ax.utils.common.logger import ROOT_STREAM_HANDLER\n",
    "\n",
    "ROOT_STREAM_HANDLER.setLevel(logging.ERROR)\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Hide future warnings because ax uses deprecated functions from pandas\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# Hide unfixable warning from ax (warns about default behavior but there isn't\n",
    "# a clear way to turn the warning off)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "LST_DATASETS = [\"boston\", \"diabetes\", \"riboflavin\"]\n",
    "\n",
    "CACHE_DIR = Path(\"ax_runs\") / \"st_selection\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DS_PATH = Path(\"..\") / \"datasets\"\n",
    "\n",
    "PARAM_PATH = Path(\".\") / \"parameters\"\n",
    "PLOT_PATH = Path(\".\") / \"plots\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {}\n",
    "\n",
    "for file in PARAM_PATH.glob(\"*.yaml\"):\n",
    "    model_info[file.stem] = yaml.safe_load(open(file, \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "def train_sklearn(\n",
    "    ModelClass,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test,\n",
    "    y_test,\n",
    "):\n",
    "    model = ModelClass(**params)\n",
    "    model.fit(x_train, y_train.flatten())\n",
    "\n",
    "    return {\n",
    "        \"train_error\": float(rmse(y_train.flatten(), model.predict(x_train))),\n",
    "        \"val_error\": float(rmse(y_val.flatten(), model.predict(x_val))),\n",
    "        \"test_error\": float(rmse(y_test.flatten(), model.predict(x_test))),\n",
    "        \"model\": model,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_lasso(params, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    res = train_sklearn(\n",
    "        Lasso,\n",
    "        params,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "    )\n",
    "\n",
    "    eps = 1e-6\n",
    "\n",
    "    return {\n",
    "        \"density\": np.mean(np.abs(res[\"model\"].coef_) > eps),\n",
    "        **res,\n",
    "    }\n",
    "\n",
    "\n",
    "def dummy_regressor(x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    dummy.fit(x_train, y_train.flatten())\n",
    "\n",
    "    return {\n",
    "        \"train_error\": float(rmse(y_train.flatten(), dummy.predict(x_train))),\n",
    "        \"val_error\": float(rmse(y_val.flatten(), dummy.predict(x_val))),\n",
    "        \"test_error\": float(rmse(y_test.flatten(), dummy.predict(x_test))),\n",
    "    }\n",
    "\n",
    "\n",
    "def train_joplen(\n",
    "    ModelType,\n",
    "    params,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test,\n",
    "    y_test,\n",
    "):\n",
    "    params = deepcopy(params)\n",
    "\n",
    "    initial_params = {\n",
    "        \"partitioner\": eval(params.pop(\"partitioner\")),\n",
    "        \"n_cells\": params.pop(\"n_cells\"),\n",
    "        \"n_partitions\": params.pop(\"n_partitions\"),\n",
    "        \"random_state\": params.pop(\"random_state\"),\n",
    "    }\n",
    "\n",
    "    initial_params[\"cell_model\"] = eval(params.pop(\"cell_model\"))\n",
    "    assert initial_params[\"cell_model\"] == CellModel.linear\n",
    "\n",
    "    model = ModelType(**initial_params)\n",
    "\n",
    "    assert \"norm_type\" in params\n",
    "\n",
    "    params[\"norm_type\"] = eval(params[\"norm_type\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        val_x=x_val,\n",
    "        val_y=y_val,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    if params[\"norm_type\"] == NormType.L21:\n",
    "        norm = l21_norm\n",
    "    elif params[\"norm_type\"] == NormType.LINF1:\n",
    "        norm = linf1_norm\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return {\n",
    "        \"train_error\": float(rmse(y_train, model.predict(x_train))),\n",
    "        \"val_error\": float(rmse(y_val, model.predict(x_val))),\n",
    "        \"test_error\": float(rmse(y_test, model.predict(x_test))),\n",
    "        \"model\": model,\n",
    "        \"epochs\": len(history),\n",
    "        \"density\": float((norm(model.w.get()) > 1e-6).mean()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_front(\n",
    "    score: np.ndarray, density: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    unique_density = np.unique(density)\n",
    "\n",
    "    pareto_score = []\n",
    "    pareto_density = []\n",
    "\n",
    "    for d in unique_density:\n",
    "        mask = density == d\n",
    "        pareto_score.append(np.min(score[mask]))\n",
    "        pareto_density.append(d)\n",
    "\n",
    "    pareto_score = np.array(pareto_score)\n",
    "    pareto_density = np.array(pareto_density)\n",
    "\n",
    "    args = np.argsort(pareto_density)\n",
    "\n",
    "    return pareto_density[args], pareto_score[args]\n",
    "\n",
    "\n",
    "def score(dummy_res, model_res, alpha):\n",
    "    res = {\n",
    "        \"error\": {\n",
    "            \"train\": model_res[\"train_error\"] / dummy_res[\"train_error\"],\n",
    "            \"val\": model_res[\"val_error\"] / dummy_res[\"val_error\"],\n",
    "            \"test\": model_res[\"test_error\"] / dummy_res[\"test_error\"],\n",
    "        },\n",
    "        \"density\": model_res[\"density\"],\n",
    "    }\n",
    "\n",
    "    res[\"pareto\"] = {\n",
    "        \"train\": alpha * res[\"density\"] + (1 - alpha) * res[\"error\"][\"train\"],\n",
    "        \"val\": alpha * res[\"density\"] + (1 - alpha) * res[\"error\"][\"val\"],\n",
    "        \"test\": alpha * res[\"density\"] + (1 - alpha) * res[\"error\"][\"test\"],\n",
    "    }\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = {\n",
    "    Lasso.__name__: train_lasso,\n",
    "    JOPLEn.__name__: train_joplen,\n",
    "}\n",
    "\n",
    "\n",
    "def optimize_model(model_info, ds_path, n_trials, minimize, loss_type, alpha):\n",
    "    ds_name = ds_path.name\n",
    "    params = model_info[\"parameters\"]\n",
    "\n",
    "    dir_path = CACHE_DIR / model_info[\"dir_name\"] / ds_name\n",
    "    exp_path = dir_path / \"experiment.json\"\n",
    "    metadata_path = dir_path / \"metadata.yaml\"\n",
    "\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        return metadata\n",
    "\n",
    "    x_train = np.loadtxt(ds_path / \"x_train.csv\", delimiter=\",\")\n",
    "    x_val = np.loadtxt(ds_path / \"x_val.csv\", delimiter=\",\")\n",
    "    x_test = np.loadtxt(ds_path / \"x_test.csv\", delimiter=\",\")\n",
    "    y_train = np.loadtxt(ds_path / \"y_train.csv\", delimiter=\",\")\n",
    "    y_val = np.loadtxt(ds_path / \"y_val.csv\", delimiter=\",\")\n",
    "    y_test = np.loadtxt(ds_path / \"y_test.csv\", delimiter=\",\")\n",
    "\n",
    "    dummy_res = dummy_regressor(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_val,\n",
    "        y_val,\n",
    "        x_test,\n",
    "        y_test,\n",
    "    )\n",
    "\n",
    "    if not exp_path.exists():\n",
    "        ax_client = AxClient(\n",
    "            random_seed=0,\n",
    "            verbose_logging=False,\n",
    "        )\n",
    "\n",
    "        ax_client.create_experiment(\n",
    "            name=model_info[\"model\"],\n",
    "            parameters=params,\n",
    "            objectives={loss_type: ObjectiveProperties(minimize=minimize)},\n",
    "            overwrite_existing_experiment=True,\n",
    "        )\n",
    "\n",
    "        for _ in range(n_trials):\n",
    "            round_params, trial_index = ax_client.get_next_trial()\n",
    "\n",
    "            try:\n",
    "                model_res = train_fn[model_info[\"model\"]](\n",
    "                    round_params,\n",
    "                    x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_val=x_val,\n",
    "                    y_val=y_val,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                )\n",
    "                model_score = score(dummy_res, model_res, alpha)\n",
    "                ax_client.complete_trial(\n",
    "                    trial_index=trial_index, raw_data=model_score[\"pareto\"][\"val\"]\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                ax_client.abandon_trial(\n",
    "                    trial_index=trial_index,\n",
    "                    reason=str(e),\n",
    "                )\n",
    "    else:\n",
    "        ax_client = AxClient.load_from_json_file(exp_path)\n",
    "\n",
    "    best_parameters, _ = ax_client.get_best_parameters()\n",
    "\n",
    "    model_res = train_fn[model_info[\"model\"]](\n",
    "        best_parameters,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "    )\n",
    "    model_score = score(dummy_res, model_res, alpha)\n",
    "\n",
    "    metadata = {\n",
    "        \"model\": {\n",
    "            \"name\": model_info[\"model\"],\n",
    "            \"results\": model_res,\n",
    "            \"score\": model_score,\n",
    "        },\n",
    "        \"dummy\": {\n",
    "            \"name\": \"DummyRegressor\",\n",
    "            **dummy_res,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_res = defaultdict(dict)\n",
    "\n",
    "alphas = np.linspace(0, 1, 6, endpoint=True)\n",
    "datasets = [DS_PATH / ds for ds in LST_DATASETS]\n",
    "itr = tqdm(alphas)\n",
    "\n",
    "for alpha in itr:\n",
    "    for ds_path in datasets:\n",
    "        for file_name, info in model_info.items():\n",
    "            if \"st_selection\" not in info[\"experiments\"]:\n",
    "                continue\n",
    "\n",
    "            model_str = f\"{file_name} on {ds_path.name}\"\n",
    "            itr.set_description(f\"Running {model_str : <50}\")\n",
    "            res = optimize_model(info, ds_path, 10, True, \"rmse\", alpha)\n",
    "\n",
    "            if res is not None:\n",
    "                reg_res[info[\"name\"]][ds_path.name].append(res)\n",
    "\n",
    "reg_res = dict(reg_res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
