{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import JOPLEn.singletask as jp\n",
    "from JOPLEn.enums import *\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from itertools import product\n",
    "from ax import optimize\n",
    "import lightgbm as lgbm\n",
    "from pathlib import Path\n",
    "from copy import copy, deepcopy\n",
    "import yaml\n",
    "import time\n",
    "from pprint import pprint\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "\n",
    "CACHE_DIR = Path(\"cache\") / \"experiments\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DS_PATH = Path(\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = [\n",
    "    {\n",
    "        \"name\": \"num_leaves\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [2, 32],\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"n_estimators\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [10, 1000],\n",
    "        \"value_type\": \"int\",\n",
    "        \"log_scale\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"learning_rate\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1e-5, 1e-1],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_split_gain\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 1.0],\n",
    "        \"value_type\": \"float\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"reg_alpha\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1e-5, 1e1],\n",
    "        \"value_type\": \"float\",\n",
    "        \"log_scale\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"reg_lambda\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1e-5, 1e1],\n",
    "        \"value_type\": \"float\",\n",
    "        \"log_scale\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"random_state\",\n",
    "        \"type\": \"fixed\",\n",
    "        \"value\": 0,\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"verbose\",\n",
    "        \"type\": \"fixed\",\n",
    "        \"value\": -1,\n",
    "        \"value_type\": \"int\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        return (result, start_time, end_time, elapsed_time)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@timer_decorator\n",
    "def train_lgbm(params, x_train, y_train, x_val, y_val, x_test=None, y_test=None):\n",
    "    lgbm = LGBMRegressor(**params)\n",
    "    lgbm.fit(\n",
    "        x_train,\n",
    "        y_train.flatten(),\n",
    "        # TODO: Need to re-enable validation set\n",
    "        # eval_set=[(x_val, y_val.flatten())],\n",
    "        # verbose=-1,\n",
    "        # callbacks=[],\n",
    "    )\n",
    "\n",
    "    val_error = float(rmse(y_val.flatten(), lgbm.predict(x_val)))\n",
    "\n",
    "    if x_test is not None and y_test is not None:\n",
    "        test_error = float(rmse(y_test.flatten(), lgbm.predict(x_test)))\n",
    "        return val_error, test_error, lgbm\n",
    "    else:\n",
    "        return val_error, lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_regressor(x_train, x_val, x_test, y_train, y_val, y_test, indent=False):\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    dummy.fit(x_train, y_train)\n",
    "    y_pred = dummy.predict(x_test)\n",
    "\n",
    "    res = {\n",
    "        \"model_name\": dummy.__class__.__name__,\n",
    "        \"rmse\": float(rmse(y_test, y_pred)),\n",
    "    }\n",
    "\n",
    "    pprint(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "\n",
    "\n",
    "def optimize_model(model_class, ds_path, n_trials, minimize, loss_type):\n",
    "    print(f\"Optimizing {model_class.__name__} on {ds_path.name}...\")\n",
    "\n",
    "    x_train = np.loadtxt(ds_path / \"x_train.csv\", delimiter=\",\")\n",
    "    x_val = np.loadtxt(ds_path / \"x_val.csv\", delimiter=\",\")\n",
    "    x_test = np.loadtxt(ds_path / \"x_test.csv\", delimiter=\",\")\n",
    "    y_train = np.loadtxt(ds_path / \"y_train.csv\", delimiter=\",\")\n",
    "    y_val = np.loadtxt(ds_path / \"y_val.csv\", delimiter=\",\")\n",
    "    y_test = np.loadtxt(ds_path / \"y_test.csv\", delimiter=\",\")\n",
    "\n",
    "    dummy_info = dummy_regressor(\n",
    "        x_train, x_val, x_test, y_train, y_val, y_test, indent=True\n",
    "    )\n",
    "\n",
    "    match model_class:\n",
    "        case lgbm.LGBMRegressor:\n",
    "            params = lgbm_params\n",
    "            train_fn = train_lgbm\n",
    "        case _:\n",
    "            raise ValueError(\"Model not yet supported.\")\n",
    "\n",
    "    exp_name = model_class.__name__ + \"_\" + ds_class.__name__\n",
    "    exp_path = Path(\"ax_runs\") / f\"{exp_name}.json\"\n",
    "\n",
    "    ax_client = AxClient(random_seed=0)\n",
    "\n",
    "    ax_client.create_experiment(\n",
    "        name=exp_name,\n",
    "        parameters=params,\n",
    "        objectives={loss_type: ObjectiveProperties(minimize=minimize)},\n",
    "        overwrite_existing_experiment=True,\n",
    "    )\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        round_params, trial_index = ax_client.get_next_trial()\n",
    "        try:\n",
    "            val_error, _ = train_fn(\n",
    "                round_params, x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val\n",
    "            )[0]\n",
    "            ax_client.complete_trial(trial_index=trial_index, raw_data=float(val_error))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            ax_client.abandon_trial(\n",
    "                trial_index=trial_index,\n",
    "                reason=str(e),\n",
    "            )\n",
    "\n",
    "    best_parameters, values = ax_client.get_best_parameters()\n",
    "\n",
    "    (val_error, test_error, _), _, _, train_time = train_fn(\n",
    "        best_parameters,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_val=x_val,\n",
    "        y_val=y_val,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "    )\n",
    "\n",
    "    exp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ax_client.save_to_json_file(\n",
    "        filepath=exp_path,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model_class.__name__,\n",
    "        \"val_score\": val_error,\n",
    "        \"test_score\": test_error,\n",
    "        \"train_time\": train_time,\n",
    "        \"params\": best_parameters,\n",
    "        \"dummy_loss\": dummy_info[\"rmse\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = optimize_model(jp.JOPLEn, NPLogP, 10, True, \"rmse\")\n",
    "res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
